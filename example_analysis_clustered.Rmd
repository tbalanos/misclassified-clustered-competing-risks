---
title: "Illustrative Example: Applying the Semiparametric Marginal Regression for Clustered Competing Risks Data with Misclassified Causes of Failure"
author:
- Theofanis Balanos^[Department of Biostatistics and Health Data Science, Fairbanks School of Public Health and School of Medicine, Indiana University Indianapolis, IN, USA]
- Giorgos Bakoyannis^[Department of Biostatistics and Health Data Science, Fairbanks School of Public Health and School of Medicine, Indiana University Indianapolis, IN, USA]
- Constantin T. Yiannoutsos^[Department of Epidemiology and Biostatistics, CUNY Graduate School of Public Health and Health Policy, City University of New York, NY, USA]
output:
  rmarkdown::html_document:
    theme: paper
header-includes: |
  \usepackage{enumerate,footnote,float,placeins,tabularx,graphicx,
  amsmath,amssymb,setspace,booktabs,epsfig,lastpage,url,hyperref,bbm,
  fancyhdr,mathtools,multirow,lscape}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

In this short document, we present an example illustrating how to use our proposed Semiparametric Marginal Regression Method for Clustered Competing Risks Data with Misclassified Causes of Failure.

## Step 1 – Generate External Validation Dataset

We start by generating a simulated external **validation dataset** for modeling misclassification probabilities in **clustered competing-risks data**. The simulation mechanism follows the framework of *Mpofu et al.* (2020) for the double-sampling pseudo-likelihood approach but is extended here to incorporate **clustering** and **informative cluster size (ICS)**, following the ideas of *Zhou et al.* (2023). This design induces correlation among individuals within clusters through shared frailty terms, while cluster sizes depend on frailty values to represent ICS.  

The resulting external dataset represents a **partially validated sample** (i.e., true causes are observed for roughly 50% of subjects). This dataset is used to **estimate the parameters of the misclassification model**, capturing how misclassification depends on time and covariates. The externally estimated misclassification probabilities are then **applied to the main analysis dataset** when fitting the proposed *semiparametric marginal regression model*.  

The data-generation procedure is contained in a separate R script, `simulate_data.R`, located on the user’s desktop.  
This script defines three main misclassification scenarios:  
1. Unidirectional misclassification  
2. Bidirectional misclassification (equal probabilities)  
3. Bidirectional misclassification (unequal probabilities)

Below, we load this simulation script, generate an **external validation dataset** under the **bidirectional (equal)** case (`cause_num = 2`), and inspect the first few rows of one example dataset.

```{r, message=FALSE, warning=FALSE}
#--- Generate a list of external validation datasets --------------------------

# Load data-generation script (extends Mpofu et al. 2020 to clustered setting)
source("/Users/theofanisbalanos/Desktop/Paper_2/Balanos2025_Method_Illustration/simulate_data.R")

# Arguments:
# n           : number of datasets to generate
# n_clusters  : number of clusters per dataset
# cause_num   : misclassification scenario
#               1 = uni-directional
#               2 = bi-directional (equal probabilities)
#               3 = bi-directional (unequal probabilities)
# ds          : proportion double-sampled (validation indicator)

external_data_list <- data_list(
  n = 1,                # number of replicate datasets
  n_clusters = 50,     # number of clusters to simulate
  cause_num = 2,        # bidirectional misclassification (equal)
  ds = 0.5              # only 50% validated
)

# Select one dataset for demonstration
dat_external <- external_data_list[[1]]

# Display first few rows of the simulated external dataset
head(dat_external)
```

### Variable Descriptions

Each simulated dataset generated by `simulate_data.R` contains the following variables.

| Variable | Description |
|-----------|-------------|
| **id** | Subject identifier (unique across all clusters). |
| **cluster_id** | Cluster identifier, denoting subjects belonging to the same cluster. |
| **Mi** | Cluster size, representing the number of subjects within each cluster. Cluster size is informative, depending on the cluster-level frailty. |
| **t** | True event time \(T\). |
| **x** | Observed follow-up time (minimum of event or censoring time). |
| **c** | True cause of failure (1 = cause 1, 2 = cause 2, 0 = censored). |
| **c_obs** | Observed (possibly misclassified) cause of failure \(C^{*}\). |
| **d1** | Indicator that the *true* cause of failure is 1 \((C=1)\). |
| **d2** | Indicator that the *true* cause of failure is 2 \((C=2)\). |
| **d1_obs** | Indicator that the *observed* cause of failure is 1 \((C^{*}=1)\). |
| **d2_obs** | Indicator that the *observed* cause of failure is 2 \((C^{*}=2)\). |
| **z1** | Continuous covariate 1 (Uniform(0, 1)). |
| **z2** | Continuous covariate 2 (Normal(0, 1)). |
| **s** | Double-sampling indicator (1 = subject selected for validation sample, 0 = not selected). |
| **r** | Indicator that the *true cause* is observed (1 = true cause known, 0 = missing). |

#### Note

All variables are fully simulated and serve only illustrative purposes.  

---

## Step 2 – Estimate Misclassification Probabilities

Next, we apply the pseudo-likelihood estimation procedure of *Mpofu et al.* (2020), extended here to accommodate **clustering** and **ICS**, to the **external validation dataset** generated in Step 1.  

This step estimates the parameters of the logistic-regression models for the predictive values and the misclassification probabilities. The estimated coefficients (\(\hat{\gamma}\)) describe how covariates \((t, z_1, z_2)\) affect the probability of misclassifying one cause as another within clusters.  

The estimation functions are defined in the external script `pseudo_likelihood_estimation_Mpofu.R`, which adapts the original approach to the clustered setting.

```{r, message=FALSE, warning=FALSE}
#--- Load Mpofu et al. (2020) pseudo-likelihood estimation functions -----------
source("/Users/theofanisbalanos/Desktop/Paper_2/Balanos2025_Method_Illustration/pseudo_likelihood_estimation_Mpofu.R")
```

### | Probability of Observing Cause 2 Given True Cause 1

In this case, we estimate the probability of observing cause 2 when the true cause of failure is 1; that is,

\[
P(C^{*}=2 \mid C=1,\, T,\, \mathbf{Z})
\]

representing misclassification from cause 1 → 2, and \(T = t\) denotes the event time and \(\mathbf{Z} = (z_1, z_2)\) represents the subject-specific covariates.

```{r, message=FALSE, warning=FALSE}
#--- Perform pseudo-likelihood estimation for cause 1 → 2 ---------------------
model_fit_example1 <- misclass_ps_est(dat = dat_external,
                                      true_out = "c",
                                      surr_out = "c_obs",
                                      out_interest = 1,
                                      formula_pred_val = ~ t + z1 + z2,
                                      formula_mis = ~ t + z1 + z2,
                                      ds_var = "r")

# Display estimated coefficients and standard errors
model_fit_example1$test_summary
```

### | Probability of Observing Cause 1 Given True Cause 2

Here, we estimate the probability of observing cause 1 when the true cause of failure is 2; that is,

\[
P(C^{*}=1 \mid C=2,\, T,\, \mathbf{Z}),
\]

representing misclassification from cause 2 → 1, and \(T = t\) denotes the event time and \(\mathbf{Z} = (z_1, z_2)\) represents the subject-specific covariates.

```{r, message=FALSE, warning=FALSE}
#--- Perform pseudo-likelihood estimation for cause 2 → 1 ---------------------
model_fit_example2 <- misclass_ps_est(dat = dat_external,
                                      true_out = "c",
                                      surr_out = "c_obs",
                                      out_interest = 2,
                                      formula_pred_val = ~ t + z1 + z2,
                                      formula_mis = ~ t + z1 + z2,
                                      ds_var = "r")

# Display estimated coefficients and standard errors
model_fit_example2$test_summary
```

---

## Step 3 – Generate Main Analysis Dataset

In this step, we generate a **main dataset** representing the study cohort in which the true causes of failure are *not observed*. Only the misclassified causes (\(C^{*}\)) are available for analysis.  
This dataset will later be analyzed using the proposed **semiparametric marginal regression method**, incorporating the **externally estimated misclassification probabilities** obtained in Step 2.  

The same clustered simulation procedure used for the external validation data (see `simulate_data.R`) is employed here, but we now set the **double-sampling proportion** (`ds = 0`) so that no subjects have their true causes observed. Clustering and ICS are again included through the frailty-based mechanism, ensuring dependence among subjects within clusters.

```{r, message=FALSE, warning=FALSE}
#--- Generate the main (analysis) dataset -------------------------------------

# Load the same simulation script (already loaded earlier, shown again for clarity)
source("/Users/theofanisbalanos/Desktop/Paper_2/Balanos2025_Method_Illustration/simulate_data.R")

# Create one main dataset with no internal validation (ds = 0)
main_data_list <- data_list(
  n = 1,                 # number of replicate datasets
  n_clusters = 50,       # number of clusters
  cause_num = 2,         # bidirectional equal misclassification
  ds = 0.0               # no double-sampling (true causes unobserved)
)

dat_main <- main_data_list[[1]]

# Display first few rows of the main dataset
head(dat_main)
```

#### Note

All variables are defined as in Step 1.

---

## Step 4 – Compute Misclassification Probabilities for the Main Dataset

We now compute the estimated misclassification probabilities for each subject in the **main analysis dataset** using the pseudo-likelihood models fitted on the external validation dataset (Step 2).  
Specifically,

- \( p_{21} = P(C^{*}=2 \mid C=1, T,\, \mathbf{Z}) \): probability that true cause 1 is observed as 2  
- \( p_{12} = P(C^{*}=1 \mid C=2, T,\, \mathbf{Z}) \): probability that true cause 2 is observed as 1

```{r, message=FALSE, warning=FALSE}
#--- Step 4: Compute predicted misclassification probabilities -----------------

# Extract Mpofu model objects from Step 2
mod_21 <- model_fit_example1$model_miscl   # C=1 → observed as 2
mod_12 <- model_fit_example2$model_miscl   # C=2 → observed as 1

# Predict misclassification probabilities in the main dataset
dat_main$p21 <- predict(mod_21, newdata = dat_main, type = "response")
dat_main$p12 <- predict(mod_12, newdata = dat_main, type = "response")

# Display first few rows with misclassification probabilities
head(dat_main[, c("t", "z1", "z2", "p12", "p21")])
```

---

## Step 5 – Apply the Proposed Semiparametric Regression Method

In this step, we apply the proposed **semiparametric marginal regression estimator** to the **main analysis dataset**. This method uses the externally estimated misclassification probabilities \( p_{12} \) and \( p_{21} \) obtained in Step 4 to correct for outcome misclassification in the cause-specific hazard estimation. The function further incorporates **clustering** and **ICS** through **inverse cluster-size weighting** \((1 / M_i)\) in the estimating equations. Within-cluster dependence is not modeled directly but will later be handled through **cluster-level bootstrap resampling** for valid inference.

The estimation function `bssmle_clustered()` is defined in the external R script `bssmle_clustered.R`.

```{r, message=FALSE, warning=FALSE}
#--- Load the proposed semiparametric regression function ---------------------
source("/Users/theofanisbalanos/Desktop/Paper_2/Balanos2025_Method_Illustration/bssmle_clustered.R")

#--- Fit the model to the main dataset ----------------------------------------
fit_bssmle <- bssmle_clustered(dat_main, covariates = c("z1", "z2"))

#--- Extract and interpret results --------------------------------------------
covariates <- c("z1", "z2")
beta_vec <- fit_bssmle
q <- length(covariates)
n <- (length(beta_vec) - 2*q) / 2
stopifnot(n == floor(n), n > 0)

phi1  <- beta_vec[1:n]
phi2  <- beta_vec[(n+1):(2*n)]
beta1 <- beta_vec[(2*n+1):(2*n+q)]
beta2 <- beta_vec[(2*n+q+1):(2*n+2*q)]

names(beta1) <- paste0("Cause1:", covariates)
names(beta2) <- paste0("Cause2:", covariates)

coef_table <- data.frame(
  cause     = rep(c("Cause 1","Cause 2"), each = q),
  covariate = rep(covariates, times = 2),
  estimate  = c(beta1, beta2)
)

cat("\nEstimated regression coefficients for each cause:\n")
print(coef_table, row.names = FALSE)
cat("\nNumber of B-spline basis coefficients per cause:", n, "\n")
```

#### Notes

* The vector `fit_bssmle` concatenates all estimated parameters in the order
  \((\phi_1, \phi_2, \beta_1, \beta_2)\).

  *  \(\phi_1, \phi_2\): spline coefficients for the two baseline hazards.
  *  \(\beta_1, \beta_2\): regression coefficients for the covariates under each cause.
* With two covariates \((z_1, z_2)\), the **last four elements** of `fit_bssmle` correspond to
  \((\beta_{1,z1}, \beta_{1,z2}, \beta_{2,z1}, \beta_{2,z2})\).
* These estimates incorporate **time- and covariate-dependent misclassification**,
  **clustering** and **ICS**, while cluster-level dependence will be addressed
  via bootstrap resampling in Step 7.

---

## Step 6 – Sensitivity Analysis for Misclassification Probabilities  

To evaluate the robustness of our clustered semiparametric regression estimator when the true misclassification rates differ from those estimated using the validation data, we conduct a sensitivity analysis following the same framework described in the data application section of the paper.  

Under this framework, the *adjusted misclassification probabilities* are defined as  
\[
\pi^*_{jh}(X,\mathbf{Z},T;\gamma_{0,h},\eta)
   = g(\gamma'_{0,h}\,\tilde{\mathbf{W}} + \eta S),
\]
where \(g(\cdot)\) is the logistic function, \(\tilde{\mathbf{W}}\) represents the covariates associated with misclassification (e.g., event time \(T\) and covariates \(\mathbf{Z}\)), and \(S\) is an indicator for the data source (\(S=0\) for the external validation dataset and \(S=1\) for the main analysis dataset). The sensitivity parameter \(\eta\) controls how much the misclassification mechanism in the main study deviates from that estimated in the validation sample. When \(\eta = 0\), **perfect transportability** is assumed, whereas \(\eta \neq 0\) reflects deviations from this assumption.  

For implementation, both estimated misclassification probabilities  
\[
p_{21} = P(C^{*}=2 \mid C=1,\,T=t,\,\mathbf{Z}), \qquad
p_{12} = P(C^{*}=1 \mid C=2,\,T=t,\,\mathbf{Z}),
\]
are modified via a **logit shift** for \(\eta \in \{-0.5,-0.25,0,0.25,0.5\}\):  
\[
\text{logit}\{p_{jh}^{(\eta)}\}
   = \text{logit}\{p_{jh}\} + \eta,
   \quad\text{so}\quad
   p_{jh}^{(\eta)} = \operatorname{logit}^{-1}\{\operatorname{logit}(p_{jh})+\eta\}.
\]

This adjustment provides an empirical counterpart to \(\pi^*_{jh}(X,\mathbf{Z},T;\gamma_{0,h},\eta) = g(\gamma'_{0,h}\tilde{\mathbf{W}}+\eta S)\) for the main analysis dataset (\(S=1\)).  

For each \(\eta\), we re-fit the **semiparametric marginal regression model** using `bssmle_clustered()` and record the resulting regression coefficients for both causes.

```{r, message=FALSE, warning=FALSE}
#--- Sensitivity analysis for clustered data (bidirectional adjustment) -------

etas <- c(-0.5, -0.25, 0, 0.25, 0.5)
covariates <- c("z1", "z2")

fit_at_eta <- function(eta, dat, covariates) {
  dat_eta <- dat

  if (abs(eta) > 1e-12) {
    eps <- 1e-12

    # Adjust p21 (C=1 → observed as 2)
    p <- pmin(pmax(dat_eta$p21, eps), 1 - eps)
    dat_eta$p21 <- plogis(qlogis(p) + eta)

    # Adjust p12 (C=2 → observed as 1)
    p <- pmin(pmax(dat_eta$p12, eps), 1 - eps)
    dat_eta$p12 <- plogis(qlogis(p) + eta)
  }
  # else leave dat_eta$p12 and dat_eta$p21 unchanged

  beta_vec <- bssmle_clustered(dat_eta, covariates)

  q <- length(covariates)
  n <- (length(beta_vec) - 2*q) / 2
  if (!is.finite(n) || n != floor(n) || n <= 0) return(NULL)

  beta1 <- beta_vec[(2*n + 1):(2*n + q)]
  beta2 <- beta_vec[(2*n + q + 1):(2*n + 2*q)]
  names(beta1) <- paste0("Cause1:", covariates)
  names(beta2) <- paste0("Cause2:", covariates)

  coef_table <- data.frame(
    eta       = eta,
    cause     = rep(c("Cause 1", "Cause 2"), each = q),
    covariate = rep(covariates, times = 2),
    estimate  = c(beta1, beta2)
  )

  cat("\nEstimated regression coefficients for each cause (eta =", eta, "):\n")
  print(coef_table, row.names = FALSE)
  return(coef_table)
}

# Run sensitivity analysis across η values
sens_list <- lapply(etas, fit_at_eta, dat = dat_main, covariates = covariates)
```

#### Note

Please note that results for \(\eta = 0\) correspond to those from Step 5, since \(\eta = 0\) represents the baseline case without any sensitivity adjustment.

---

## Step 7 – Cluster Bootstrap for Standard Errors

To assess the sampling variability of the proposed **marginal semiparametric estimator**, we perform a **cluster-level bootstrap**. In this procedure, entire clusters are resampled (with replacement) from the **main clustered dataset**, and the model is re-fit on each bootstrap replicate. For demonstration, we use **10 bootstrap samples**, but users can increase this number (e.g., 100 or 1000) depending on computational resources and needs. Each bootstrap fit returns a full parameter vector; the standard deviation of these estimates provides approximate standard errors.  

Please note that the bootstrap is conducted only for the baseline case with \(\eta=0\) (the model estimated in Step 5), not for the sensitivity analyses in Step 6.

```{r, message=FALSE, warning=FALSE}
#-------------------------#
#  Cluster Bootstrap Code
#-------------------------#

# Load packages for parallel computation
library(doParallel)
library(foreach)

set.seed(2026)     # Set seed for reproducibility
n_boot <- 10       # Number of bootstrap replicates (increase for more precision)
mc <- 10           # Number of parallel cores to use

# --- Identify the correct cluster column name ---
cluster_var <- if ("center" %in% names(dat_main)) "center" else
               if ("cluster_id" %in% names(dat_main)) "cluster_id" else
               stop("No cluster column named 'center' or 'cluster_id' found.")

# --- Fit the model once on the original data to get point estimates ---
th_dir <- try(bssmle_clustered(dat_main, covariates = c("z1","z2")), silent = TRUE)
if (inherits(th_dir, "try-error") || is.null(th_dir)) {
  stop("Direct fit failed — please check that bssmle_clustered() runs correctly on dat_main.")
}

# Extract all unique cluster IDs from the dataset
cluster_ids <- unique(dat_main[[cluster_var]])

# --- Start parallel cluster bootstrap ---
registerDoParallel(cores = mc)

boot_res <- foreach(b = 1:n_boot, .combine = rbind, .inorder = FALSE,
                    .packages = c("alabama","splines","survival","geepack","stabledist")) %dopar% {

  # 1. Resample clusters (with replacement)
  resampled_ids <- sample(cluster_ids, length(cluster_ids), replace = TRUE)

  # 2. Create bootstrap sample by combining all subjects from each chosen cluster
  boot_sample <- do.call(rbind, lapply(resampled_ids, function(cid) {
    dat_main[ dat_main[[cluster_var]] == cid, ]
  }))

  # 3. Check if valid
  if (is.null(boot_sample) || nrow(boot_sample) == 0 ||
      !all(c("z1","z2","p12","p21") %in% names(boot_sample))) {
    return(rep(NA_real_, 4))
  }

  # 4. Reindex clusters
  boot_sample[[cluster_var]] <- as.numeric(factor(boot_sample[[cluster_var]]))

  # 5. Fit model on bootstrap sample
  th <- try(bssmle_clustered(boot_sample, covariates = c("z1","z2")), silent = TRUE)

  # 6. Return last 4 regression coefficients
  if (inherits(th, "try-error") || is.null(th) || all(is.na(th))) {
    rep(NA_real_, 4)
  } else {
    tail(th, 4)
  }
}

stopImplicitCluster()

# --- Handle bootstrap failures ---
if (all(is.na(boot_res))) stop("All bootstrap fits failed — check model inputs or cluster variable name.")

# --- Compute Wald-based statistics ---
p_estimate <- tail(th_dir, 4)  # direct-fit regression coefficients
boot_sds   <- apply(boot_res, 2, sd, na.rm = TRUE)

# Wald statistics
z_value <- p_estimate / boot_sds
p_value <- 2 * (1 - pnorm(abs(z_value)))
Lower95 <- p_estimate - 1.96 * boot_sds
Upper95 <- p_estimate + 1.96 * boot_sds

# --- Create clean summary table ---
q <- 2
boot_table <- data.frame(
  cause     = rep(c("Cause 1","Cause 2"), each = q),
  covariate = rep(c("z1","z2"), times = 2),
  estimate  = p_estimate,
  SE        = boot_sds,
  z_value   = z_value,
  p_value   = p_value,
  Lower95   = Lower95,
  Upper95   = Upper95
)

knitr::kable(
  boot_table,
  digits = c(NA, NA, 3, 3, 3, 3, 3, 3),
  caption = "Cluster-bootstrap Wald inference for regression coefficients (10 replicates)."
)
```

#### Notes

* Clusters, not individual subjects, are resampled to preserve within-cluster correlation.
* The number of bootstrap replicates (`n_boot`) and parallel cores (`mc`) can be increased for greater accuracy and speed.

**Tip for readers:**
Use `n_boot = 100` for quick evaluation or `n_boot = 1000` for publication-grade inference.

---

## Step 8 – Plotting Cumulative Incidence Functions (CIFs) Across η Values

In this final step, we examine how the estimated **cumulative incidence functions (CIFs)** vary under different sensitivity settings for the parameter \(\eta\). This parameter controls the deviation between the misclassification mechanism in the main study and that estimated from the external validation data. By refitting the **marginal semiparametric regression model for clustered competing risks** using five values of \(\eta \in \{-0.5, -0.25, 0, 0.25, 0.5\}\), we visualize how predicted event probabilities evolve under weaker or stronger transportability assumptions for the misclassification model.

We compute CIFs for a **representative subject**, where the continuous covariates \(z_1\) and \(z_2\) are set to their sample means. For each \(\eta\), the function `bssmle_clustered()` is re-fitted using the adjusted misclassification probabilities, and the resulting spline and regression estimates are used to reconstruct the **marginal baseline hazards**, **cause-specific hazards** and **CIFs** over a fine time grid.

For each cause \( j = 1, 2 \):
\[
\hat{\Lambda}_{0j}(t) = \exp\{ \mathbf{B}(t)^{\top} \hat{\boldsymbol{\phi}}_j \},
\]
where \(\mathbf{B}(t)\) denotes the B-spline basis functions and \(\hat{\boldsymbol{\phi}}_j\) the corresponding spline coefficients.
The marginal cumulative hazard and survival functions are
\[
\hat{\Lambda}_j(t \mid \mathbf{Z}) = \hat{\Lambda}_{0j}(t) \exp(\mathbf{Z}^{\top}\hat{\boldsymbol{\beta}}_j),
\]
and   
\[
\hat{S}(t \mid \mathbf{Z}) = \exp\!\left[-\sum_{j=1}^{2}\hat{\Lambda}_j(t \mid \mathbf{Z})\right].
\]
Finally, the cumulative incidence for cause \(j\) is obtained by numerical integration:
\[
\hat{F}_j(t \mid \mathbf{Z}) = \int_0^t \hat{S}(u \mid \mathbf{Z})\, d\hat{\Lambda}_j(u \mid \mathbf{Z}),
\]
which we approximate using cumulative sums over a fine grid. These formulas correspond to the **marginal proportional cause-specific hazards formulation** described in the paper.

The plots below display one panel per cause of failure. The x-axis shows time, and the y-axis the estimated event probability. Each line represents a specific \(\eta\) value, illustrating how sensitive the CIFs are to changes in the assumed misclassification mechanism.

```{r, message=FALSE, warning=FALSE}
#-----------------------------------------------#
# Plot CIFs for the Five η Scenarios
#-----------------------------------------------#

library(splines)
library(parallel)   # for using multiple cores

# Sensitivity parameters to test
etas <- c(-0.5, -0.25, 0, 0.25, 0.5)  # sensitivity shift values
covariates <- c("z1", "z2")           # covariates used in the model

# Define a representative subject profile:
#   z1 = mean of the continuous covariate,
#   z2 = mean of the continuous covariate
Z1 <- c(mean(dat_main$z1, na.rm = TRUE), mean(dat_main$z2, na.rm = TRUE))
Z2 <- Z1

# Detect how many cores your machine has
num_cores <- detectCores() - 1   # leave 1 core free

# Create a cluster of workers
cl <- makeCluster(num_cores)

# Export necessary objects/functions to each worker
clusterExport(cl, c("dat_main", "bssmle_clustered", "naive_b", "covariates"))
invisible(clusterEvalQ(cl, library(splines)))

# Parallel loop — each worker runs one η value
fit_eta <- parLapply(cl, etas, function(eta) {
  dat_eta <- dat_main
  eps <- 1e-12  # avoid log(0)
  
  # Adjust misclassification probabilities
  dat_eta$p21 <- plogis(qlogis(pmin(pmax(dat_eta$p21, eps), 1 - eps)) + eta)
  dat_eta$p12 <- plogis(qlogis(pmin(pmax(dat_eta$p12, eps), 1 - eps)) + eta)
  
  # Fit the clustered semiparametric model
  bssmle_clustered(dat_eta, covariates = covariates)
})

# Stop cluster after finishing
stopCluster(cl)

# Name the fitted models
names(fit_eta) <- paste0("eta_", etas)

# --- Build spline basis for the time grid ---
# This recreates the same spline setup used during model estimation (see function `bssmle_clustered()`)
t_fit <- dat_main$x
nk <- floor(length(t_fit)^(1/3))                              # number of interior knots
knots_fit <- quantile(t_fit, seq(0, 1, by = 1/(nk + 1)))[2:(nk + 1)]
bkn_fit   <- range(t_fit, na.rm = TRUE)
deg_fit   <- 3                                                # cubic B-splines
t_grid <- seq(bkn_fit[1], bkn_fit[2], length.out = 200)       # fine time grid
Bpred  <- bs(t_grid, knots = knots_fit, degree = deg_fit,
             intercept = TRUE, Boundary.knots = bkn_fit)
dt <- c(0, diff(t_grid))                                      # time step differences

# --- Function to compute CIFs from model coefficients ---
# Uses baseline hazard splines and covariate effects to get F1(t) and F2(t)
compute_cif <- function(res, Bpred, Z1, Z2, t_grid, dt) {
  n  <- (length(res) - 4) / 2
  phi1 <- res[1:n]; phi2 <- res[(n+1):(2*n)]
  b1   <- res[(2*n+1):(2*n+2)]; b2 <- res[(2*n+3):(2*n+4)]
  
  # Baseline cumulative hazards
  H01 <- exp(Bpred %*% phi1)
  H02 <- exp(Bpred %*% phi2)
  
  # Subject-specific cumulative hazards
  lp1 <- sum(Z1 * b1); lp2 <- sum(Z2 * b2)
  H1 <- H01 * exp(lp1)
  H2 <- H02 * exp(lp2)
  
  # Instantaneous hazards and CIFs
  h1 <- c(0, diff(H1)) / dt
  h2 <- c(0, diff(H2)) / dt
  h1[!is.finite(h1)] <- 0; h2[!is.finite(h2)] <- 0
  
  S_t <- exp(-(H1 + H2))             # survival function
  F1  <- cumsum(S_t * h1 * dt)       # CIF for cause 1
  F2  <- cumsum(S_t * h2 * dt)       # CIF for cause 2
  list(F1 = F1, F2 = F2)
}

# --- Compute CIFs for all η values ---
cif_list <- lapply(fit_eta, compute_cif, Bpred = Bpred,
                   Z1 = Z1, Z2 = Z2, t_grid = t_grid, dt = dt)

# --- Plot the CIFs for each cause ---
# y-axis fixed between 0 and 1 for comparability
par(mfrow = c(1, 2), mar = c(4.5, 4.5, 3, 1))
cols <- gray.colors(length(etas), start = 0.1, end = 0.7)

## (a) Cause 1
plot(t_grid, cif_list[[1]]$F1, type = "l", lwd = 2, ylim = c(0, 1),
     xlab = "Time", ylab = "Cumulative incidence function",
     main = "(a) Cause 1")
for (i in seq_along(etas)) {
  lines(t_grid, cif_list[[i]]$F1, col = cols[i], lwd = 2, lty = i)
}
legend("topleft", legend = sapply(etas, \(e) bquote(eta == .(e))),
       col = cols, lwd = 2, lty = seq_along(etas),
       bty = "n", cex = 0.8)

## (b) Cause 2
plot(t_grid, cif_list[[1]]$F2, type = "l", lwd = 2, ylim = c(0, 1),
     xlab = "Time", ylab = "Cumulative incidence function",
     main = "(b) Cause 2")
for (i in seq_along(etas)) {
  lines(t_grid, cif_list[[i]]$F2, col = cols[i], lwd = 2, lty = i)
}
legend("topleft", legend = sapply(etas, \(e) bquote(eta == .(e))),
       col = cols, lwd = 2, lty = seq_along(etas),
       bty = "n", cex = 0.8)
```

---

## Concluding Remarks

This example demonstrated the use of our **marginal semiparametric regression method for clustered competing risks data with misclassified causes of failure**. Using simulated clustered data, we estimated misclassification probabilities from an external validation sample, applied the `bssmle_clustered()` estimator and examined sensitivity to transportability assumptions through the parameter \(\eta\). The method adjusts for **misclassification**, **within-cluster dependence** and **informative cluster size**, producing valid marginal cause-specific effects and cumulative incidence estimates. Overall, it provides a flexible and practical framework for analyzing real-world clustered competing-risks data where outcome misclassification is likely.

